{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dbnesuUHRCco"
   },
   "outputs": [],
   "source": [
    "# Step 1: Training a Model for BSL Alphabets with GPU and Data Augmentation\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywFg5A8nRCcq",
    "outputId": "27d6cc6b-896b-4ea2-a0b9-2ab81ba4af87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOaJOuKLRCcq",
    "outputId": "b6da0b22-9b7c-4881-a662-d4600b4e65e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lr3lMHfvRCcq"
   },
   "outputs": [],
   "source": [
    "# Setup data directories\n",
    "data_dir = \"./BSL/BSL\"  # Replace with the path to your BSL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LGWLCUdzRCcq"
   },
   "outputs": [],
   "source": [
    "# Prepare ImageDataGenerator for training and validation data with specific data augmentation\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "9NqrjkFNRCcr",
    "outputId": "6b97cfa7-90d8-47ab-9332-04e5d50332be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4020 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = datagen_train.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "_tBCLGQ0RCcr",
    "outputId": "c77c8540-c445-498c-ee76-05e1d3fcd21c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 993 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = datagen_train.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "KBH_Z2DoRCcr",
    "outputId": "ccf988ca-bda8-4efc-bcde-14469df4617b"
   },
   "outputs": [],
   "source": [
    "# Model architecture (deeper with more CNN and pooling layers)\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(512, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_data.num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = train_data.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(128, 128, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # num_classes should be defined\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1  # Optional for more detailed logs\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=3, \n",
    "    verbose=1,  # Optional for more detailed logs\n",
    "    min_lr=1e-6  # Ensures the learning rate does not go too low\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "mTreKwIkRCcs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "126/126 [==============================] - 39s 265ms/step - loss: 5.4515 - accuracy: 0.0552 - val_loss: 9.7359 - val_accuracy: 0.0423 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 32s 256ms/step - loss: 4.4225 - accuracy: 0.0542 - val_loss: 7.8722 - val_accuracy: 0.0383 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 32s 256ms/step - loss: 4.2413 - accuracy: 0.0545 - val_loss: 18.6536 - val_accuracy: 0.0403 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 32s 254ms/step - loss: 4.1033 - accuracy: 0.0552 - val_loss: 14.9754 - val_accuracy: 0.0453 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 32s 254ms/step - loss: 3.9424 - accuracy: 0.0607 - val_loss: 4.4674 - val_accuracy: 0.0655 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 32s 252ms/step - loss: 3.8439 - accuracy: 0.0572 - val_loss: 5.2402 - val_accuracy: 0.0483 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 32s 254ms/step - loss: 3.7792 - accuracy: 0.0604 - val_loss: 3.7586 - val_accuracy: 0.0524 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 32s 253ms/step - loss: 3.8110 - accuracy: 0.0565 - val_loss: 12.6221 - val_accuracy: 0.0675 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 32s 256ms/step - loss: 3.8214 - accuracy: 0.0600 - val_loss: 3.8047 - val_accuracy: 0.0614 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 3.7123 - accuracy: 0.0595\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "126/126 [==============================] - 34s 266ms/step - loss: 3.7123 - accuracy: 0.0595 - val_loss: 9.0428 - val_accuracy: 0.0594 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 33s 265ms/step - loss: 3.6190 - accuracy: 0.0600 - val_loss: 3.9019 - val_accuracy: 0.0957 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - 32s 257ms/step - loss: 3.5223 - accuracy: 0.0657 - val_loss: 3.6615 - val_accuracy: 0.0816 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - 33s 264ms/step - loss: 3.4206 - accuracy: 0.0739 - val_loss: 3.3804 - val_accuracy: 0.1098 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 34s 265ms/step - loss: 3.3182 - accuracy: 0.0818 - val_loss: 3.7622 - val_accuracy: 0.1259 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "126/126 [==============================] - 32s 256ms/step - loss: 3.2255 - accuracy: 0.0975 - val_loss: 3.7106 - val_accuracy: 0.1027 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 32s 252ms/step - loss: 3.2078 - accuracy: 0.1204 - val_loss: 3.3063 - val_accuracy: 0.1128 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 32s 257ms/step - loss: 3.1153 - accuracy: 0.1386 - val_loss: 4.4494 - val_accuracy: 0.1138 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - 32s 252ms/step - loss: 2.9372 - accuracy: 0.1617 - val_loss: 3.6003 - val_accuracy: 0.1279 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 2.8074 - accuracy: 0.2022\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "126/126 [==============================] - 32s 256ms/step - loss: 2.8074 - accuracy: 0.2022 - val_loss: 3.5568 - val_accuracy: 0.1873 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 32s 253ms/step - loss: 2.5589 - accuracy: 0.2565 - val_loss: 2.9580 - val_accuracy: 0.2417 - lr: 2.5000e-04\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 33s 258ms/step - loss: 2.3668 - accuracy: 0.3251 - val_loss: 2.3126 - val_accuracy: 0.4391 - lr: 2.5000e-04\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 32s 253ms/step - loss: 2.1423 - accuracy: 0.3863 - val_loss: 2.7201 - val_accuracy: 0.3585 - lr: 2.5000e-04\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 513s 4s/step - loss: 1.9336 - accuracy: 0.4510 - val_loss: 4.7534 - val_accuracy: 0.1400 - lr: 2.5000e-04\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 34s 266ms/step - loss: 1.7567 - accuracy: 0.5206 - val_loss: 1.7373 - val_accuracy: 0.5911 - lr: 2.5000e-04\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 33s 260ms/step - loss: 1.5835 - accuracy: 0.5706 - val_loss: 2.8318 - val_accuracy: 0.3988 - lr: 2.5000e-04\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 32s 255ms/step - loss: 1.4440 - accuracy: 0.6246 - val_loss: 1.5830 - val_accuracy: 0.6133 - lr: 2.5000e-04\n",
      "Epoch 27/50\n",
      "126/126 [==============================] - 34s 271ms/step - loss: 1.3504 - accuracy: 0.6530 - val_loss: 1.8475 - val_accuracy: 0.6103 - lr: 2.5000e-04\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 32s 255ms/step - loss: 1.2255 - accuracy: 0.6955 - val_loss: 1.9788 - val_accuracy: 0.5791 - lr: 2.5000e-04\n",
      "Epoch 29/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 1.1684 - accuracy: 0.7229\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "126/126 [==============================] - 34s 270ms/step - loss: 1.1684 - accuracy: 0.7229 - val_loss: 1.5910 - val_accuracy: 0.6636 - lr: 2.5000e-04\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - 33s 264ms/step - loss: 1.0494 - accuracy: 0.7654 - val_loss: 1.4663 - val_accuracy: 0.7009 - lr: 1.2500e-04\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 33s 264ms/step - loss: 0.9767 - accuracy: 0.8015 - val_loss: 1.3013 - val_accuracy: 0.7442 - lr: 1.2500e-04\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 32s 255ms/step - loss: 0.9398 - accuracy: 0.8032 - val_loss: 1.1785 - val_accuracy: 0.7805 - lr: 1.2500e-04\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 33s 262ms/step - loss: 0.8740 - accuracy: 0.8236 - val_loss: 1.1314 - val_accuracy: 0.7905 - lr: 1.2500e-04\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 33s 261ms/step - loss: 0.8344 - accuracy: 0.8398 - val_loss: 1.1556 - val_accuracy: 0.7946 - lr: 1.2500e-04\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 32s 255ms/step - loss: 0.8413 - accuracy: 0.8346 - val_loss: 1.4135 - val_accuracy: 0.7482 - lr: 1.2500e-04\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 33s 258ms/step - loss: 0.7952 - accuracy: 0.8542 - val_loss: 1.1006 - val_accuracy: 0.8127 - lr: 1.2500e-04\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 33s 264ms/step - loss: 0.7878 - accuracy: 0.8562 - val_loss: 1.0358 - val_accuracy: 0.8117 - lr: 1.2500e-04\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 33s 261ms/step - loss: 0.7358 - accuracy: 0.8786 - val_loss: 0.8642 - val_accuracy: 0.8691 - lr: 1.2500e-04\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 33s 264ms/step - loss: 0.6948 - accuracy: 0.8900 - val_loss: 1.2377 - val_accuracy: 0.7966 - lr: 1.2500e-04\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 33s 262ms/step - loss: 0.6800 - accuracy: 0.8883 - val_loss: 0.8777 - val_accuracy: 0.8479 - lr: 1.2500e-04\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.6535 - accuracy: 0.9012\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "126/126 [==============================] - 34s 266ms/step - loss: 0.6535 - accuracy: 0.9012 - val_loss: 1.5878 - val_accuracy: 0.7321 - lr: 1.2500e-04\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 32s 257ms/step - loss: 0.6385 - accuracy: 0.9037 - val_loss: 1.3240 - val_accuracy: 0.7946 - lr: 6.2500e-05\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.6220 - accuracy: 0.9104Restoring model weights from the end of the best epoch: 38.\n",
      "126/126 [==============================] - 33s 262ms/step - loss: 0.6220 - accuracy: 0.9104 - val_loss: 1.0127 - val_accuracy: 0.8338 - lr: 6.2500e-05\n",
      "Epoch 43: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compile the model to use GPU if available\n",
    "with tf.device('/device:GPU:0'):\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # Training\n",
    "    model.fit(train_data, epochs=50, validation_data=val_data, callbacks=[early_stopping, reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "vPuMZoQKRCcs"
   },
   "outputs": [],
   "source": [
    "# Save model for inference later\n",
    "model.save('bsl_alphabet1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Clear the session to release GPU memory\n",
    "K.clear_session()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
